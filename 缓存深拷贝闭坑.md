# 缓存深拷贝闭坑：从 RocksDB 到 BigCache/Redis

---

## 一、问题背景

项目中用 RocksDB 作为持久化存储，BigCache/Redis 作为高性能缓存。
你可能会遇到这样的问题：

* **从缓存读取的数据被业务层修改，下次读取时数据已被污染，导致 BUG 难以定位。**
* **但直接从 RocksDB 读取时，无论业务怎么改，数据始终不会被“带脏”。**

本文通过对比、原理分析、代码复现、最佳实践，彻底闭坑！

---

## 二、现象复现

### 2.1 RocksDB 读取（安全）

```go
value, _ := db.Get(key)
var obj MyStruct
_ = sonic.Unmarshal(value, &obj)
obj.Field = "A" // 只影响 obj
```

> 下次 db.Get(key)，数据依然是初始快照，不受 obj 改动影响。

---

### 2.2 缓存读取（易污染）

```go
var items []*Ad
val, _ := bc.Get("ads_key")
_ = sonic.Unmarshal(val, &items)
items[0].Name = "脏数据"
```

> 下次任何地方 get 同样的缓存 key，读取到的 items\[0].Name 已变为“脏数据”，影响全局。

---

## 三、底层原理对比

| 机制    | RocksDB/持久化 DB | BigCache/Redis 等缓存 |
| ----- | -------------- | ------------------ |
| 存储内容  | 二进制快照 \[]byte  | 结构体指针/序列化结果        |
| 读取方式  | 每次反序列化新对象      | 反序列化/引用返回          |
| 业务层改动 | 不影响后续读取        | 可能污染全局             |
| 多协程场景 | 天然安全           | 全局污染难以排查           |

**说明：**

* RocksDB 每次反序列化\[]byte，业务侧永远是“新副本”。
* 缓存区往往是全局唯一对象/切片，直接暴露给业务层，谁都能改。

---

## 四、如何复现缓存污染

1. **写入缓存**

   ```go
   ads := []*Ad{
       {Id: "1", Name: "Ad1"},
       {Id: "2", Name: "Ad2"},
   }
   data, _ := sonic.Marshal(ads)
   _ = bc.Set("cache_ads", data)
   ```

2. **读取并修改对象**

   ```go
   var items []*Ad
   val, _ := bc.Get("cache_ads")
   _ = sonic.Unmarshal(val, &items)
   items[0].Name = "Polluted"
   ```

3. **再次读取**

   ```go
   var again []*Ad
   val, _ = bc.Get("cache_ads")
   _ = sonic.Unmarshal(val, &again)
   fmt.Println(again[0].Name) // => "Polluted"，不是"Ad1"
   ```

---

## 五、为什么 RocksDB 没这个问题？

* RocksDB 永远存的是二进制快照，每次 Get 后 Unmarshal 总是新对象。
* 无论你怎么改业务对象，下一次读出来的还是初始状态，“污染”不会传染。

---

## 六、根本解决方案（深拷贝 DeepCopy）

只要缓存返回的数据有可能被业务改动，**必须 Marshal+Unmarshal 深拷贝后再 return！**

**推荐代码模板：**

```go
var cached []*Ad
val, _ := bc.Get("cache_ads")
_ = sonic.Unmarshal(val, &cached)

// DeepCopy
if data, err := sonic.Marshal(cached); err == nil {
    var safe []*Ad
    if sonic.Unmarshal(data, &safe) == nil {
        return safe // 业务可放心修改
    }
}
```

* Sonic 性能极高，比标准库 json 更适合高并发场景。
* 深拷贝后业务再怎么赋值/append/改字段，都不影响缓存区对象。

---

## 七、团队标准与最佳实践

* 所有缓存、全局变量、静态池化返回的数据，都要 deep copy 一份给业务层。

* 统一用 sonic.Marshal/Unmarshal（支持结构体嵌套、切片、map 等复杂结构）。

* 推荐封装通用 deep copy 工具函数：

  ```go
  func DeepCopy[T any](src T) T {
      data, _ := sonic.Marshal(src)
      var dst T
      _ = sonic.Unmarshal(data, &dst)
      return dst
  }
  ```

* 遇到 interface{} 字段需特别处理，否则序列化会 panic。

* RocksDB/DB 本身不会有对象污染风险，只需关注缓存和全局变量的隔离。

---

## 八、常见问答

**Q: 为什么 DB/持久化每次 get 都没脏数据？**
A: 每次都是新序列化/反序列化，内存没有共享引用，业务操作互不影响。

**Q: 为什么缓存/全局变量这么容易污染？**
A: 缓存区是进程唯一副本，所有协程/模块都能访问并直接更改。

**Q: Marshal/Unmarshal 性能会拖慢接口吗？**
A: 用 Sonic 影响极小，远比业务线上崩溃和数据错乱代价小得多。

---

## 九、闭坑自检 Checklist

* [x] 所有缓存 get 后是否都做了 deep copy？
* [x] 结构体有无 interface{}、裸指针等不易序列化的字段？
* [x] 新人/全员是否了解缓存脏数据危害？
* [x] 代码 review 时有无检查缓存读取后的数据流向？

---

## 十、结论（强制规范）

> RocksDB/DB 每次读都不怕脏数据，缓存一定要 deep copy。
> 团队标准：所有从缓存区返回的对象必须 DeepCopy，才能彻底闭坑高并发下的数据污染！

---

*如需团队 Wiki/Lark/Confluence 适配，或实际代码审查疑难点，欢迎随时补充交流。*
